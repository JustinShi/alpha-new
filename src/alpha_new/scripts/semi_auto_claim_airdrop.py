import asyncio
from datetime import datetime, timedelta
import glob
import json
import os
from pathlib import Path
import time

import httpx
import toml

from alpha_new.api.alpha_api import AlphaAPI
from alpha_new.db.models import init_db
from alpha_new.db.ops import get_user_by_id, get_valid_users
from alpha_new.utils import get_claim_logger

logger = get_claim_logger()

BINANCE_TIME_API = "https://api.binance.com/api/v3/time"


def save_network_log(
    log_type: str,
    user_id: int | None,
    request_info: dict,
    response_data: dict | None,
    error: str | None = None,
):
    """ä¿å­˜ç½‘ç»œè¯·æ±‚æ—¥å¿—åˆ°ç»Ÿä¸€çš„.logæ–‡ä»¶"""
    try:
        # ç¡®ä¿logsç›®å½•å­˜åœ¨
        os.makedirs("logs", exist_ok=True)

        # ç»Ÿä¸€çš„æ—¥å¿—æ–‡ä»¶è·¯å¾„
        log_path = "logs/network_requests.log"

        # æ ¼å¼åŒ–æ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]

        # æ„å»ºæ—¥å¿—è¡Œ
        log_line_parts = [
            f"[{timestamp}]",
            f"[{log_type.upper()}]",
            f"[USER:{user_id or 'SYSTEM'}]",
        ]

        # æ·»åŠ è¯·æ±‚ä¿¡æ¯
        if request_info:
            request_str = " ".join([f"{k}={v}" for k, v in request_info.items()])
            log_line_parts.append(f"REQUEST: {request_str}")

        # æ·»åŠ å“åº”ä¿¡æ¯
        if response_data:
            response_str = json.dumps(
                response_data, ensure_ascii=False, separators=(",", ":")
            )
            log_line_parts.append(f"RESPONSE: {response_str}")

        # æ·»åŠ é”™è¯¯ä¿¡æ¯
        if error:
            log_line_parts.append(f"ERROR: {error}")

        # ç»„åˆå®Œæ•´çš„æ—¥å¿—è¡Œ
        log_line = " | ".join(log_line_parts) + "\n"

        # è¿½åŠ å†™å…¥æ—¥å¿—æ–‡ä»¶
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(log_line)

        logger.debug(f"ğŸ’¾ ç½‘ç»œè¯·æ±‚æ—¥å¿—å·²è¿½åŠ åˆ°: {log_path}")
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜ç½‘ç»œè¯·æ±‚æ—¥å¿—å¤±è´¥: {e}")


CHECK_INTERVAL = 0.02  # 20msï¼Œæ›´é«˜ç²¾åº¦
CONFIG_PATH = "config/airdrop_config.toml"
ADVANCE_MS = 120  # æå‰120æ¯«ç§’å‘èµ·é¢†å–è¯·æ±‚ï¼ŒæŠµæ¶ˆç½‘ç»œå»¶è¿Ÿ


async def get_binance_time() -> datetime:
    async with httpx.AsyncClient() as client:
        try:
            logger.info(f"ğŸŒ è¯·æ±‚å¸å®‰æ—¶é—´API: {BINANCE_TIME_API}")
            request_info = {"url": BINANCE_TIME_API, "method": "GET"}
            resp = await client.get(BINANCE_TIME_API)
            response_data = resp.json()
            logger.info(
                f"ğŸ“¥ å¸å®‰æ—¶é—´APIå“åº”: serverTime={response_data.get('serverTime')}"
            )

            # ä¿å­˜ç½‘ç»œè¯·æ±‚æ—¥å¿—
            save_network_log("binance_time", None, request_info, response_data)

            server_time = response_data["serverTime"]  # æ¯«ç§’
            return datetime.fromtimestamp(server_time / 1000)
        except Exception as e:
            logger.error(f"âŒ å¸å®‰æ—¶é—´APIè¯·æ±‚å¤±è´¥: {e}")
            # ä¿å­˜é”™è¯¯æ—¥å¿—
            save_network_log(
                "binance_time",
                None,
                {"url": BINANCE_TIME_API, "method": "GET"},
                None,
                str(e),
            )
            raise


def get_next_target_time(hour: int, minute: int, second: int) -> datetime:
    now = datetime.now()
    target = now.replace(hour=hour, minute=minute, second=second, microsecond=0)
    if target <= now:
        target += timedelta(days=1)
    return target


def decode_dict(d) -> dict[str, str]:
    if not d:
        return {}
    return {
        k.decode() if isinstance(k, bytes) else k: v.decode()
        if isinstance(v, bytes)
        else v
        for k, v in d.items()
    }


async def find_config_id(
    user_id: int, token_symbol: str, alpha_id: str = ""
) -> str | None:
    json_path = Path("data/airdrop_list.json")
    if json_path.exists():
        with open(json_path, encoding="utf-8") as f:
            data = json.load(f)
            for config in data.get("data", {}).get("configs", []):
                if (token_symbol and config.get("tokenSymbol") == token_symbol) or (
                    alpha_id and config.get("alphaId") == alpha_id
                ):
                    return config.get("configId")
    return None


async def query_config_id(
    api: AlphaAPI, token_symbol: str, alpha_id: str = ""
) -> str | None:
    for attempt in range(1, 11):  # æœ€å¤šæŸ¥10æ¬¡
        try:
            logger.info(
                f"ğŸ” æŸ¥è¯¢ç©ºæŠ•é…ç½®ID (å°è¯• {attempt}/10): token_symbol={token_symbol}, alpha_id={alpha_id}"
            )
            request_info = {
                "api_method": "query_airdrop_list",
                "token_symbol": token_symbol,
                "alpha_id": alpha_id,
                "attempt": attempt,
            }
            airdrop_list = await api.query_airdrop_list()
            config_count = len(airdrop_list.get("data", {}).get("configs", []))
            logger.info(f"ğŸ“¥ ç©ºæŠ•åˆ—è¡¨APIå“åº”: æ‰¾åˆ°{config_count}ä¸ªé…ç½®")

            # ä¿å­˜ç½‘ç»œè¯·æ±‚æ—¥å¿—
            save_network_log(
                "query_airdrop_list", api.user_id, request_info, airdrop_list
            )

            for config in airdrop_list.get("data", {}).get("configs", []):
                if (token_symbol and config.get("tokenSymbol") == token_symbol) or (
                    alpha_id and config.get("alphaId") == alpha_id
                ):
                    config_id = config.get("configId")
                    logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…çš„é…ç½®ID: {config_id}")
                    return config_id

            logger.warning(f"âš ï¸ ç¬¬{attempt}æ¬¡æŸ¥è¯¢æœªæ‰¾åˆ°åŒ¹é…çš„é…ç½®")
            await asyncio.sleep(0.5)
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢ç©ºæŠ•é…ç½®IDå¤±è´¥ (å°è¯• {attempt}/10): {e}")
            # ä¿å­˜é”™è¯¯æ—¥å¿—
            save_network_log(
                "query_airdrop_list",
                api.user_id,
                {"api_method": "query_airdrop_list", "attempt": attempt},
                None,
                str(e),
            )
            await asyncio.sleep(0.5)

    logger.error("âŒ æŸ¥è¯¢é…ç½®IDå¤±è´¥ï¼Œå·²å°è¯•10æ¬¡")
    return None


async def calibrate_time_offset(repeat=5):
    offsets = []
    for _ in range(repeat):
        t0 = time.time()
        server_time = (await get_binance_time()).timestamp()
        t1 = time.time()
        local_time = (t0 + t1) / 2
        offsets.append(server_time - local_time)
        await asyncio.sleep(0.1)
    return sum(offsets) / len(offsets)


async def claim_for_user(
    user_id: int,
    token_symbol: str,
    alpha_id: str,
    target_dt: datetime,
    engine,
    retry_times: int = 3,
    retry_interval: int = 1,
    time_offset: float = 0.0,
) -> tuple[int, str]:
    from sqlalchemy.ext.asyncio import async_sessionmaker

    async_session = async_sessionmaker(engine, expire_on_commit=False)
    async with async_session() as session:
        user = await get_user_by_id(session, user_id)
        if not user:
            return user_id, f"[ç”¨æˆ·{user_id}] ä¸å­˜åœ¨"
        headers = decode_dict(user.headers) if user.headers is not None else {}
        cookies = decode_dict(user.cookies) if user.cookies is not None else None
        api = AlphaAPI(headers=headers, cookies=cookies, user_id=user_id)
        config_id = await find_config_id(user_id, token_symbol, alpha_id)
        if not config_id:
            config_id = await query_config_id(api, token_symbol, alpha_id)
        if not config_id:
            return user_id, f"[ç”¨æˆ·{user_id}] æœªæŸ¥åˆ°configIdï¼Œæ”¾å¼ƒé¢†å–"
        # æ¯«ç§’çº§å®šæ—¶é¢†å–ï¼ˆæœ¬åœ°+offsetåˆ¤æ–­ï¼Œæå‰è¡¥å¿ï¼‰
        while True:
            now = datetime.now().timestamp() + time_offset
            delta = target_dt.timestamp() - now
            if delta <= ADVANCE_MS / 1000:
                logger.info(
                    f"[ç”¨æˆ·{user_id}] è§¦å‘é¢†å–æ—¶åˆ»(æœ¬åœ°æ ¡å‡†): {datetime.fromtimestamp(now).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}ï¼Œæå‰è¡¥å¿: {ADVANCE_MS}ms"
                )
                break
            await asyncio.sleep(0.005)  # 5msç²¾åº¦
        result = None
        for attempt in range(1, retry_times + 1):
            try:
                # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
                request_start = time.time()
                logger.info(
                    f"ğŸš€ ç”¨æˆ·{user_id}å‘èµ·é¢†å–è¯·æ±‚ (å°è¯• {attempt}/{retry_times}): config_id={config_id}"
                )
                request_info = {
                    "api_method": "claim_airdrop",
                    "config_id": config_id,
                    "attempt": attempt,
                    "user_id": user_id,
                }
                result = await api.claim_airdrop(config_id)
                # è®°å½•è¯·æ±‚ç»“æŸæ—¶é—´å’Œå»¶è¿Ÿ
                request_end = time.time()
                network_delay = (request_end - request_start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                logger.info(f"â±ï¸ ç”¨æˆ·{user_id}APIè¯·æ±‚å»¶è¿Ÿ: {network_delay:.0f}ms")

                # ç®€åŒ–å“åº”æ—¥å¿—æ˜¾ç¤º
                result_code = result.get("code", "unknown")
                result_msg = result.get("message", "")
                claim_status = (
                    result.get("data", {}).get("claimStatus", "")
                    if result.get("data")
                    else ""
                )
                logger.info(
                    f"ğŸ“¥ ç”¨æˆ·{user_id}é¢†å–APIå“åº”: code={result_code}, message={result_msg}, claimStatus={claim_status}"
                )

                # ä¿å­˜ç½‘ç»œè¯·æ±‚æ—¥å¿—ï¼ˆåŒ…å«å»¶è¿Ÿä¿¡æ¯ï¼‰
                request_info["network_delay_ms"] = network_delay
                save_network_log("claim_airdrop", user_id, request_info, result)

                # åˆ¤æ–­é¢†å–æˆåŠŸæˆ–å·²é¢†å–ç­‰ç»ˆæ­¢æ¡ä»¶
                if result.get("code") == "000000" or (
                    result.get("data")
                    and result.get("data").get("claimStatus") in ["success", "claimed"]
                ):
                    logger.info(f"âœ… ç”¨æˆ·{user_id}é¢†å–è¯·æ±‚æˆåŠŸï¼Œåœæ­¢é‡è¯•")
                    break
                logger.warning(f"âš ï¸ ç”¨æˆ·{user_id}é¢†å–è¯·æ±‚æœªæˆåŠŸï¼Œå‡†å¤‡é‡è¯•")
            except Exception as e:
                logger.error(
                    f"âŒ ç”¨æˆ·{user_id}é¢†å–è¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt}/{retry_times}): {e}"
                )
                # ä¿å­˜é”™è¯¯æ—¥å¿—
                save_network_log(
                    "claim_airdrop",
                    user_id,
                    {
                        "api_method": "claim_airdrop",
                        "config_id": config_id,
                        "attempt": attempt,
                    },
                    None,
                    str(e),
                )
                if attempt == retry_times:
                    return user_id, f"[ç”¨æˆ·{user_id}] é¢†å–å¼‚å¸¸: {e}"
            if attempt < retry_times:
                logger.info(f"â³ ç”¨æˆ·{user_id}ç­‰å¾…{retry_interval}ç§’åé‡è¯•...")
                await asyncio.sleep(retry_interval)

        # æ³¨æ„ï¼šå“åº”æ•°æ®å·²é€šè¿‡save_network_logä¿å­˜åˆ°logs/network_requests.log
        if result and result.get("code") == "000000":
            return user_id, f"[ç”¨æˆ·{user_id}] é¢†å–æˆåŠŸ"
        msg = result.get("message", "æœªçŸ¥é”™è¯¯") if result else "æ— è¿”å›"
        return user_id, f"[ç”¨æˆ·{user_id}] é¢†å–å¤±è´¥: {msg}"


async def get_user_score(user_id: int, engine) -> int:
    from sqlalchemy.ext.asyncio import async_sessionmaker

    async_session = async_sessionmaker(engine, expire_on_commit=False)
    async with async_session() as session:
        user = await get_user_by_id(session, user_id)
        if not user:
            logger.warning(f"âš ï¸ ç”¨æˆ·{user_id}ä¸å­˜åœ¨")
            return 0
        headers = decode_dict(user.headers) if user.headers is not None else {}
        cookies = decode_dict(user.cookies) if user.cookies is not None else None
        api = AlphaAPI(headers=headers, cookies=cookies)
        try:
            logger.info(f"ğŸ” æŸ¥è¯¢ç”¨æˆ·{user_id}ç§¯åˆ†")
            request_info = {"api_method": "get_alpha_score", "user_id": user_id}
            score_data = await api.get_alpha_score()
            score = int(score_data["data"].get("sumScore", 0))
            logger.info(f"ğŸ“¥ ç”¨æˆ·{user_id}ç§¯åˆ†APIå“åº”: sumScore={score}")

            # ä¿å­˜ç½‘ç»œè¯·æ±‚æ—¥å¿—
            save_network_log("get_alpha_score", user_id, request_info, score_data)

            logger.info(f"âœ… ç”¨æˆ·{user_id}å½“å‰ç§¯åˆ†: {score}")
            return score
        except Exception as e:
            logger.error(f"âŒ ç”¨æˆ·{user_id}æŸ¥è¯¢ç§¯åˆ†å¤±è´¥: {e}")
            # ä¿å­˜é”™è¯¯æ—¥å¿—
            save_network_log(
                "get_alpha_score",
                user_id,
                {"api_method": "get_alpha_score"},
                None,
                str(e),
            )
            return 0


async def countdown_loop(target_dt: datetime, time_offset: float):
    last_print = None
    while True:
        now = datetime.now().timestamp() + time_offset
        delta = target_dt.timestamp() - now
        if int(delta) != last_print and delta >= 0:
            logger.info(
                f"[æœåŠ¡å™¨æ—¶é—´(æ ¡å‡†)] {datetime.fromtimestamp(now).strftime('%Y-%m-%d %H:%M:%S')} è·ç›®æ ‡è¿˜å‰© {delta:.2f} ç§’"
            )
            last_print = int(delta)
        if delta <= 0:
            logger.info("åˆ°è¾¾ç›®æ ‡æ—¶é—´ï¼")
            break
        await asyncio.sleep(CHECK_INTERVAL)


async def main() -> None:
    # è¯»å–é…ç½®
    config = toml.load(CONFIG_PATH)
    token_symbol = config.get("token_symbol", "")
    alpha_id = config.get("alpha_id", "")
    hour, minute, second = (
        config.get("target_hour", 19),
        config.get("target_minute", 0),
        config.get("target_second", 0),
    )
    min_score = config.get("min_score", 0)
    claim_retry_times = config.get("claim_retry_times", 3)
    claim_retry_interval = config.get("claim_retry_interval", 1)
    engine = await init_db("sqlite+aiosqlite:///data/alpha_users.db")
    target_dt = get_next_target_time(hour, minute, second)
    logger.info("æ­£åœ¨æ ¡å‡†æœ¬åœ°ä¸æœåŠ¡å™¨æ—¶é—´å·®...")
    time_offset = await calibrate_time_offset()
    logger.info(f"æœ¬åœ°ä¸æœåŠ¡å™¨æ—¶é—´å·®(æœ¬åœ°+offsetâ‰ˆæœåŠ¡å™¨): {time_offset:.3f} ç§’")
    # è‡ªåŠ¨è·å–æ‰€æœ‰ç”¨æˆ·id
    from sqlalchemy.ext.asyncio import async_sessionmaker

    async_session = async_sessionmaker(engine, expire_on_commit=False)
    async with async_session() as session:
        users = await get_valid_users(session)
        user_ids = [user.id for user in users]
    logger.info(f"æ£€æµ‹åˆ°æ•°æ®åº“ç”¨æˆ·: {user_ids}")
    # æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·ç§¯åˆ†ï¼Œç­›é€‰è¾¾æ ‡ç”¨æˆ·
    logger.info("æ­£åœ¨æŸ¥è¯¢æ‰€æœ‰ç”¨æˆ·ç§¯åˆ†...")
    user_score_tasks = [get_user_score(uid, engine) for uid in user_ids]
    scores = await asyncio.gather(*user_score_tasks)
    valid_users = [
        uid for uid, score in zip(user_ids, scores, strict=False) if score >= min_score
    ]
    logger.info(f"è¾¾æ ‡ç”¨æˆ·: {valid_users}")
    if not valid_users:
        logger.warning("æ— ç”¨æˆ·ç§¯åˆ†è¾¾æ ‡ï¼Œæµç¨‹ç»“æŸã€‚")
        return
    # ç²¾ç¡®å€’è®¡æ—¶å’Œå¹¶å‘ç›‘æ§å¹¶è¡Œ
    countdown_task = asyncio.create_task(countdown_loop(target_dt, time_offset))
    claim_task = None
    claim_task_started = False
    while True:
        now = datetime.now().timestamp() + time_offset
        delta = target_dt.timestamp() - now
        if not claim_task_started and delta <= 30:
            logger.info("è·ç¦»ç›®æ ‡æ—¶é—´30ç§’ï¼Œå¯åŠ¨å¤šç”¨æˆ·å¹¶å‘ç›‘æ§...")
            claim_coros = [
                claim_for_user(
                    uid,
                    token_symbol,
                    alpha_id,
                    target_dt,
                    engine,
                    claim_retry_times,
                    claim_retry_interval,
                    time_offset,
                )
                for uid in valid_users
            ]
            claim_task = asyncio.gather(*claim_coros)
            claim_task_started = True
        if delta <= 0:
            break
        await asyncio.sleep(CHECK_INTERVAL)
    await countdown_task
    # æ—¥å¿—è‡ªåŠ¨æ¸…ç†é€»è¾‘
    data_dir = "data"
    today = datetime.now().date()
    # 1. åªä¿ç•™æœ€è¿‘7å¤©çš„åˆå¹¶æ—¥å¿—
    keep_days = 7
    for path in glob.glob(os.path.join(data_dir, "claim_log_*.json")):
        # è·³è¿‡ç”¨æˆ·åˆ†æ—¥å¿—
        if "_" in os.path.basename(path)[10:]:
            continue
        # æå–æ—¥æœŸ
        try:
            date_str = os.path.basename(path)[10:18]
            file_date = datetime.strptime(date_str, "%Y%m%d").date()
            if (today - file_date).days >= keep_days:
                os.remove(path)
        except Exception:
            pass
    # 2. åˆ é™¤æ‰€æœ‰æ—§çš„å•ç‹¬ç”¨æˆ·æ—¥å¿—æ–‡ä»¶ï¼ˆç°åœ¨ç»Ÿä¸€ä½¿ç”¨æ±‡æ€»æ–‡ä»¶ï¼‰
    logs_dir = "logs"
    for path in glob.glob(os.path.join(logs_dir, "claim_log_*_*.log")):
        os.remove(path)
        logger.info(f"æ¸…ç†æ—§çš„å•ç‹¬æ—¥å¿—æ–‡ä»¶: {path}")
    if claim_task:
        claim_results = await claim_task
        # åˆå¹¶å†™å…¥å•ä¸€æ—¥å¿—æ–‡ä»¶
        os.makedirs("logs", exist_ok=True)
        log_date = datetime.now().strftime("%Y%m%d")
        log_path = f"logs/claim_results_{log_date}.log"

        # è¿½åŠ æœ¬æ¬¡ç»“æœåˆ°æ—¥å¿—æ–‡ä»¶
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(f"\n=== åŠè‡ªåŠ¨ç©ºæŠ•é¢†å–ç»“æœ - {current_time} ===\n")
            for res_uid, msg in claim_results:
                f.write(f"[{current_time}] [USER:{res_uid}] {msg}\n")
            f.write("=" * 50 + "\n")
        # æŒ‰ç”¨æˆ·IDé¡ºåºè¾“å‡º
        for uid in sorted(valid_users):
            for res_uid, msg in claim_results:
                if res_uid == uid:
                    print(msg)
                    break


if __name__ == "__main__":
    asyncio.run(main())
